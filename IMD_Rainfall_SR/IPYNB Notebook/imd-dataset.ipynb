{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6398067,"sourceType":"datasetVersion","datasetId":3688652},{"sourceId":6398082,"sourceType":"datasetVersion","datasetId":3688663}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nstrategy = tf.distribute.MirroredStrategy()\n!pip install basemap\n!pip install basemap-data\nimport pandas as pd\nimport numpy as np\nfrom numpy import expand_dims\nimport numpy.ma as ma\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport matplotlib.cm as mtpltcm\nfrom mpl_toolkits.mplot3d import Axes3D\nimport random\nimport folium\nfrom folium.plugins import HeatMap, HeatMapWithTime\nfrom folium import plugins\nfrom netCDF4 import Dataset\nimport cartopy.crs as ccrs\nimport pydub\nfrom scipy.io.wavfile import read, write\nimport librosa\nimport librosa.display\nimport IPython\nfrom IPython.display import Audio\nimport scipy\nfrom scipy import signal\nfrom scipy.fft import fftshift\n#from mpl_toolkits.basemap import Basemap\n\nfrom warnings import filterwarnings\n\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)\nfilterwarnings(\"ignore\", category=RuntimeWarning)\n\nimport os \nimport glob\nNETCDF_PATH1 = \"/kaggle/input/imdpunelowres/\"\nNETCDF_PATH2= \"/kaggle/input/imdpunehighres/\"\nfiles1 = glob.glob(os.path.join(NETCDF_PATH1, \"*.nc\"))\nfiles2= glob.glob(os.path.join(NETCDF_PATH2, \"*.nc\"))\nprint(files1)\nprint(files2)\n\nNETCDF_lowres= [Dataset(file,more=\"r\") for file in files1]\nNETCDF_highres= [Dataset(file,more=\"r\") for file in files2]\n\nHigh_Res_dataset=[]\nLow_Res_dataset=[]\nfor i in range(len(NETCDF_lowres)):\n    for j in range(NETCDF_lowres[i].variables[\"RAINFALL\"].shape[0]):\n        Datapoint=np.array(NETCDF_lowres[i].variables[\"RAINFALL\"][j,:,:])\n        if (np.amax(Datapoint)!=0):\n            Datapoint=Datapoint/np.amax(Datapoint)\n        Datapoint[Datapoint<0]=-1.0\n        Datapoint=Datapoint[1:,1:-2]\n        Low_Res_dataset.append(Datapoint)\n    for j in range(NETCDF_highres[i].variables[\"RAINFALL\"].shape[0]):\n        Datapoint=np.array(NETCDF_highres[i].variables[\"RAINFALL\"][j,:,:])\n        if (np.amax(Datapoint)!=0):\n            Datapoint=Datapoint/np.amax(Datapoint)\n        Datapoint[Datapoint<0]=-1.0\n        Datapoint=Datapoint[1:,3:-4]\n        High_Res_dataset.append(Datapoint)\n\nLow_Res_dataset=np.array(Low_Res_dataset)\nHigh_Res_dataset=np.array(High_Res_dataset)\nHigh_Res_dataset = expand_dims(High_Res_dataset, axis=-1)\nLow_Res_dataset = expand_dims(Low_Res_dataset, axis=-1)\nHigh_Res_dataset = High_Res_dataset.astype('float32')\nLow_Res_dataset = Low_Res_dataset.astype('float32')\n#High_Res_dataset=(High_Res_dataset)/999\n#Low_Res_dataset=(Low_Res_dataset)/999\n\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom numpy import expand_dims\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randn\nfrom numpy.random import randint\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import Reshape\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Add\nfrom keras.layers import AveragePooling2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dropout\nfrom keras.layers import Embedding\nfrom keras.layers import Concatenate\nfrom keras.layers import GaussianNoise\nfrom keras.layers import BatchNormalization\nfrom keras.layers import LayerNormalization\n\nfrom keras.initializers import RandomNormal\nimport keras.backend as K\n\n# define the standalone discriminator model\ndef define_discriminator(in_shape=(128,128,1), n_classes=10):\n\t# label input\n  #in_label = Input(shape=(1,))\n\t# embedding the label input\n  #li = Embedding(n_classes, 50)(in_label)\n\t# scale up to image dimensions with linear activation\n  #n_nodes = in_shape[0]*in_shape[1]\n  #li = Dense(n_nodes)(li)\n\t# reshape to additional channel\n  #li = Reshape((in_shape[0], in_shape[1], 1))(li)\n  # image input\n  in_img = Input(shape=in_shape)\n  #KERNEL INItialization\n  init = RandomNormal(mean=0.0, stddev=0.02)\n  #in_image = Concatenate()([in_img,li])\n  in_image=GaussianNoise(0.01)(in_img)\n  #add a convolutional layers\n  fe = Conv2D(64, (3,3), strides=(1,1), padding='same',kernel_initializer=init)(in_image)\n  fe = LayerNormalization()(fe)\n  fe = LeakyReLU(alpha=0.2)(fe)\n  # add 1st residual layer to the discriminator\n  pre_fe = Conv2D(64, (3,3), strides=(1,1), padding='same',kernel_initializer=init)(fe)\n  pre_fe = LayerNormalization()(pre_fe)\n  pre_fe = LeakyReLU(alpha=0.2)(pre_fe)\n  # add 2nd residual layer to the discriminator\n  pre_fe=Conv2D(64, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(pre_fe)\n  pre_fe = LayerNormalization()(pre_fe)\n  res_lay1 = Add()([fe, pre_fe])\n  res_lay1 = LeakyReLU(alpha=0.2)(res_lay1)\n  # downsample\n  fe = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(res_lay1)\n  fe = LayerNormalization()(fe)\n  fe = LeakyReLU(alpha=0.2)(fe)\n  fe = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(fe)\n  fe = LayerNormalization()(fe)\n  fe = LeakyReLU(alpha=0.2)(fe)\n  fe = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(fe)\n  fe = LayerNormalization()(fe)\n  fe = LeakyReLU(alpha=0.2)(fe)  \n  # add 1st residual layer to the discriminator\n  #post_fe=Conv2D(128, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(fe)\n  #post_fe = BatchNormalization(synchronized=False)(post_fe)\n  #post_fe = LeakyReLU(alpha=0.2)(post_fe)\n  # add 2nd residual layer to the discriminator\n  #post_fe=Conv2D(128, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(post_fe)\n  #post_fe = BatchNormalization(synchronized=False)(post_fe)\n  #res_lay2 = Add()([fe, post_fe])\n  #res_lay2 = LeakyReLU(alpha=0.2)(res_lay2)\n\t#downsample\n  fe = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(fe)\n  fe = LayerNormalization()(fe)\n  fe = LeakyReLU(alpha=0.2)(fe)\n\t# flatten feature maps\n  fe = Flatten()(fe)\n\t# dropout\n  fe = Dropout(0.3)(fe)\n  # output\n  out_layer = Dense(1)(fe)\n\t# define model\n  model = Model(inputs=in_img, outputs= out_layer, name=\"discriminator\")\n\t# compile model\n  #opt = Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.9) #try beta_1=0 as well\n  #model.compile(loss= discloss, optimizer=opt, metrics=['accuracy'])\n  return model\n\n# define the standalone generator model\ndef define_generator(low_res=(32,32,1), n_classes=10):\n\t  # label input\n    #in_label = Input(shape=(1,))\n\t# embedding the label input\n    #li = Embedding(n_classes, 50)(in_label)\n\t# scale up to image dimensions with linear activation\n    #n_nodes = low_res[0]*low_res[1]\n    #li = Dense(n_nodes)(li)\n\t# reshape to additional channel\n    #li = Reshape((low_res[0], low_res[1], 1))(li)\n    # image generator input\n    in_img = Input(shape=low_res)\n    #in_image= Concatenate()([in_img,li])\n    input_img=GaussianNoise(0.01)(in_img)\n    init = RandomNormal(mean=0.0, stddev=0.02)\n    #add initial conv2d layer\n    fir_gen = Conv2D(64, (3,3), strides=(1,1), padding='same',kernel_initializer=init)(input_img)\n    fir_gen = BatchNormalization(synchronized=False)(fir_gen)\n    fir_gen = LeakyReLU(alpha=0.2)(fir_gen)\n    # add 1st residual layer to the generator\n    pre_gen = Conv2D(64, (3,3), strides=(1,1), padding='same',kernel_initializer=init)(fir_gen)\n    pre_gen = BatchNormalization(synchronized=False)(pre_gen)\n    pre_gen = LeakyReLU(alpha=0.2)(pre_gen)\n    # add 2nd residual layer to the generator\n    pre_gen = Conv2D(64, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(pre_gen)\n    pre_gen = BatchNormalization(synchronized=False)(pre_gen)\n    pre_gen = Add()([fir_gen, pre_gen])\n    pre_gen = LeakyReLU(alpha=0.2)(pre_gen)\n    # upsample to 28x28\n    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(pre_gen)\n    gen = BatchNormalization(synchronized=False)(gen)\n    gen = LeakyReLU(alpha=0.2)(gen)\n    #2nd upsampling\n    gen2 = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n    gen2 = BatchNormalization(synchronized=False)(gen2)\n    gen2 = LeakyReLU(alpha=0.2)(gen2)\n  # output\n    out_layer = Conv2D(1, (5,5), activation='tanh', padding='same')(gen2)\n\t# define model\n    model = Model(inputs=in_img, outputs=out_layer, name=\"generator\")\n    return model\n\n\n\n# define the combined generator and discriminator model, for updating the generator\n#def define_gan(g_model, d_model):\n\t# make weights in the discriminator not trainable\n\t#d_model.trainable = False\n\t# get noise and label inputs from generator model\n\t#gen_noise, gen_label = g_model.input\n\t# get image output from the generator model\n\t#gen_output = g_model.output\n\t# connect image output and label input from generator as inputs to discriminator\n\t#gan_output = d_model([gen_output, gen_label])\n\t# define gan model as taking noise and label and outputting a classification\n\t#model = Model([gen_noise, gen_label], gan_output)\n\t# compile model\n\t##opt = Adam(learning_rate=0.0001, beta_1=0.2)\n\t#model.compile(loss='binary_crossentropy', optimizer=opt)\n\t#return model\n\n\n\nclass WGAN(keras.Model):\n    def __init__(self, discriminator, generator, Dsteps=3, gp_weight=10.0):\n        super(WGAN, self).__init__()\n\n        self.discriminator = discriminator\n        self.generator = generator\n        self.d_steps = Dsteps\n        self.gp_weight = gp_weight\n\n    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n        super(WGAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.d_loss_fn = d_loss_fn\n        self.g_loss_fn = g_loss_fn\n    \n    \n    def gradient_penalty (self,batch_size, real_images, fake_images):\n        # Get the interpolated image\n        #print(real_images.shape)\n        #print(fake_images.shape)\n        alpha = tf.random.uniform(shape=[1,1,1], minval=0.,maxval=1.)\n        diff = fake_images - real_images\n        interpolated = real_images + alpha * diff\n\n        with tf.GradientTape() as gp_tape:\n            gp_tape.watch(interpolated)\n            pred = self.discriminator(interpolated, training=True)\n\n        grads = gp_tape.gradient(pred, [interpolated])[0]\n        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n        gp = tf.reduce_mean((norm - 1.0) ** 2)\n        return gp                             \n\n    def train_step(self, data):\n        real_images = data[0]\n        lowres_images=data[1]\n        for i in range(self.d_steps):\n            # Get the lowres image\n            #lowres_images= self.generate_low_res_samples(real_images, real_labels)\n            with tf.GradientTape() as tape:\n                # Generate fake images from the latent vector\n                fake_images = self.generator(lowres_images, training=True)\n                # Get the logits for the fake images\n                fake_logits = self.discriminator(fake_images, training=True)\n                # Get the logits for the real images\n                real_logits = self.discriminator(real_images, training=True)\n                # Calculate the discriminator loss using the fake and real image logits\n                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n                # Calculate the gradient penalty\n                gp = self.gradient_penalty(batch_size, real_images, fake_images)\n                # Add the gradient penalty to the original discriminator loss\n                d_loss = d_cost + gp * self.gp_weight\n                # Get the gradients w.r.t the discriminator loss\n                d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n                # Update the weights of the discriminator using the discriminator optimizer\n                self.d_optimizer.apply_gradients(zip(d_gradient, self.discriminator.trainable_variables))\n        # Train the generator\n        #lowres_images= self.generate_low_res_samples(real_images)\n        with tf.GradientTape() as tape:\n            # Generate fake images using the generator\n            generated_images = self.generator(lowres_images, training=True)\n            # Get the discriminator logits for fake images\n            gen_img_logits = self.discriminator(generated_images, training=True)\n            # Calculate the generator loss\n            g_loss = self.g_loss_fn(gen_img_logits)\n        # Get the gradients w.r.t the generator loss\n        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n        # Update the weights of the generator using the generator optimizer\n        self.g_optimizer.apply_gradients(zip(gen_gradient, self.generator.trainable_variables))\n        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n\n\n# load  mnist images\n#def load_samples(MNIST_DATA):\n\t# load dataset\n #   (trainX, trainy), (_, _) = MNIST_DATA.load_data()\n\t# expand to 3d, e.g. add channels\n  #  X = expand_dims(trainX, axis=-1)\n   # trainy = expand_dims(trainy, axis=-1)\n\t# convert from ints to floats\n#    X = X.astype('float32')\n\t# scale from [0,255] to [-1,1]\n #   X = (X - 127.5) / 127.5\n    #print(X.shape, trainy.shape)\n  #  return [X, trainy]\n\n#def generate_low_res_samples():\n #     [images, labels]= \n #     Avgpool= AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')\n #     ix = randint(0, images.shape[0], batch_size)\n #     # select images\n #     random_images= images[ix]\n #     labels=labels[ix]\n #     low1=Avgpool(random_images)\n #     low2=Avgpool(low1)\n      #print(low2.shape)\n #     return low2,labels\n\nclass GANMonitor(keras.callbacks.Callback):\n    def __init__(self, num_img=6):\n        self.num_img = num_img\n\n    def on_epoch_end(self, epoch, logs=None):\n        g_model.save('WGAN_GP_RAINFALL%.1f.keras'%epoch)\n\n#cbk = GANMonitor(num_img=3)\n#loading the data \n#org_dataset = load_samples(MNIST_DATA)\n#print(org_dataset[1].shape)\n#print(train_images.type, train_labels.type)\n# define the generator and the discriminator model\n#g_model=define_generator()\n#d_model= define_discriminator()\n\n#define the optimizer for the generator(G) and discriminator(D)\n\n\n#Loss functions for G and D without the Gradient penalty\n\n\n# Instantiate the WGAN model.\nwith strategy.scope():\n    cbk = GANMonitor(num_img=3)\n    g_model=define_generator()\n    d_model= define_discriminator()\n    generator_optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n    discriminator_optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n    def discriminator_loss(real_img, fake_img):\n      real_loss = tf.reduce_mean(real_img)\n      fake_loss = tf.reduce_mean(fake_img)\n      return fake_loss - real_loss\n\n    def generator_loss(fake_img):\n      return -tf.reduce_mean(fake_img)\n    wgan = WGAN(discriminator=d_model, generator=g_model, Dsteps=3,)\n    wgan.compile(d_optimizer=discriminator_optimizer, g_optimizer=generator_optimizer, g_loss_fn=generator_loss, d_loss_fn=discriminator_loss,)\n# Compile the WGAN model.\n\nepoch =50\n\ntotal_samples=High_Res_dataset.shape[0]\nprint(High_Res_dataset[0].shape, Low_Res_dataset[0].shape)\nbatch_size=32\nsteps_per_epoch=total_samples//batch_size\n#HighRes = tf.data.Dataset.from_tensor_slices(High_Res_dataset)\n#HighRes = dataset.shuffle(buffer_size=1024).batch(batch_size)\n#LowRes = tf.data.Dataset.from_tensor_slices(Low_Res_dataset)\n#LowRes = dataset.shuffle(buffer_size=1024).batch(batch_size)\n\n# Start training the model.\nwgan.fit(High_Res_dataset,Low_Res_dataset, batch_size=batch_size, epochs=epoch,callbacks=[cbk],steps_per_epoch=steps_per_epoch)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T06:32:24.975955Z","iopub.execute_input":"2023-09-12T06:32:24.976233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom numpy import expand_dims\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randn\nfrom numpy.random import randint\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import Reshape\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Add\nfrom keras.layers import AveragePooling2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dropout\nfrom keras.layers import Embedding\nfrom keras.layers import Concatenate\nfrom keras.layers import GaussianNoise\nfrom keras.layers import BatchNormalization\nfrom keras.layers import LayerNormalization\n\nfrom keras.initializers import RandomNormal\nimport keras.backend as K\n# define the standalone discriminator model\ndef define_discriminator(in_shape=(128,128,1), n_classes=10):\n\t# label input\n  #in_label = Input(shape=(1,))\n\t# embedding the label input\n  #li = Embedding(n_classes, 50)(in_label)\n\t# scale up to image dimensions with linear activation\n  #n_nodes = in_shape[0]*in_shape[1]\n  #li = Dense(n_nodes)(li)\n\t# reshape to additional channel\n  #li = Reshape((in_shape[0], in_shape[1], 1))(li)\n  # image input\n  in_img = Input(shape=in_shape)\n  #KERNEL INItialization\n  #init = RandomNormal(mean=0.0, stddev=0.02)\n  #in_image = Concatenate()([in_img,li])\n  in_image=GaussianNoise(0.01)(in_img)\n  #add a convolutional layers\n  fe = Conv2D(64, (3,3), strides=(1,1), padding='same')(in_image)\n  fe = LayerNormalization()(fe)\n  fe = LeakyReLU(alpha=0.2)(fe)\n  # add 1st residual layer to the discriminator\n  pre_fe = Conv2D(64, (3,3), strides=(1,1), padding='same')(fe)\n  pre_fe = LayerNormalization()(pre_fe)\n  pre_fe = LeakyReLU(alpha=0.2)(pre_fe)\n  # add 2nd residual layer to the discriminator\n  pre_fe=Conv2D(64, (3,3), strides=(1,1), padding='same')(pre_fe)\n  pre_fe = LayerNormalization()(pre_fe)\n  res_lay1 = Add()([fe, pre_fe])\n  res_lay1 = LeakyReLU(alpha=0.2)(res_lay1)\n  # downsample\n  fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(res_lay1)\n  fe = LayerNormalization()(fe)\n  fe = LeakyReLU(alpha=0.2)(fe)\n  fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n  fe = LayerNormalization()(fe)\n  fe = LeakyReLU(alpha=0.2)(fe)\n  fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n  fe = LayerNormalization()(fe)\n  fe = LeakyReLU(alpha=0.2)(fe)  \n  # add 1st residual layer to the discriminator\n  #post_fe=Conv2D(128, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(fe)\n  #post_fe = BatchNormalization(synchronized=False)(post_fe)\n  #post_fe = LeakyReLU(alpha=0.2)(post_fe)\n  # add 2nd residual layer to the discriminator\n  #post_fe=Conv2D(128, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(post_fe)\n  #post_fe = BatchNormalization(synchronized=False)(post_fe)\n  #res_lay2 = Add()([fe, post_fe])\n  #res_lay2 = LeakyReLU(alpha=0.2)(res_lay2)\n\t#downsample\n  fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n  fe = LayerNormalization()(fe)\n  fe = LeakyReLU(alpha=0.2)(fe)\n\t# flatten feature maps\n  fe = Flatten()(fe)\n\t# dropout\n  fe = Dropout(0.3)(fe)\n  # output\n  out_layer = Dense(1)(fe)\n\t# define model\n  model = Model(inputs=in_img, outputs= out_layer, name=\"discriminator\")\n\t# compile model\n  #opt = Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.9) #try beta_1=0 as well\n  #model.compile(loss= discloss, optimizer=opt, metrics=['accuracy'])\n  model.summary()\n  return model\n\n# define the standalone generator model\ndef define_generator(low_res=(32,32,1), n_classes=10):\n\t  # label input\n    #in_label = Input(shape=(1,))\n\t# embedding the label input\n    #li = Embedding(n_classes, 50)(in_label)\n\t# scale up to image dimensions with linear activation\n    #n_nodes = low_res[0]*low_res[1]\n    #li = Dense(n_nodes)(li)\n\t# reshape to additional channel\n    #li = Reshape((low_res[0], low_res[1], 1))(li)\n    # image generator input\n    in_img = Input(shape=low_res)\n    #in_image= Concatenate()([in_img,li])\n    input_img=GaussianNoise(0.01)(in_img)\n    #init = RandomNormal(mean=0.0, stddev=0.02)\n    #add initial conv2d layer\n    fir_gen = Conv2D(64, (3,3), strides=(1,1), padding='same')(input_img)\n    fir_gen = BatchNormalization(synchronized=False)(fir_gen)\n    fir_gen = LeakyReLU(alpha=0.2)(fir_gen)\n    # add 1st residual layer to the generator\n    pre_gen = Conv2D(64, (3,3), strides=(1,1), padding='same')(fir_gen)\n    pre_gen = BatchNormalization(synchronized=False)(pre_gen)\n    pre_gen = LeakyReLU(alpha=0.2)(pre_gen)\n    # add 2nd residual layer to the generator\n    pre_gen = Conv2D(64, (3,3), strides=(1,1), padding='same')(pre_gen)\n    pre_gen = BatchNormalization(synchronized=False)(pre_gen)\n    pre_gen = Add()([fir_gen, pre_gen])\n    pre_gen = LeakyReLU(alpha=0.2)(pre_gen)\n    # upsample to 28x28\n    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(pre_gen)\n    gen = BatchNormalization(synchronized=False)(gen)\n    gen = LeakyReLU(alpha=0.2)(gen)\n    #2nd upsampling\n    gen2 = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n    gen2 = BatchNormalization(synchronized=False)(gen2)\n    gen2 = LeakyReLU(alpha=0.2)(gen2)\n  # output\n    out_layer = Conv2D(1, (5,5), activation='tanh', padding='same')(gen2)\n\t# define model\n    model = Model(inputs=in_img, outputs=out_layer, name=\"generator\")\n    model.summary()\n    return model\ng_model=define_generator()\nd_model= define_discriminator()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T07:13:34.472999Z","iopub.execute_input":"2023-09-15T07:13:34.473403Z","iopub.status.idle":"2023-09-15T07:13:35.218016Z","shell.execute_reply.started":"2023-09-15T07:13:34.473375Z","shell.execute_reply":"2023-09-15T07:13:35.217111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nstrategy = tf.distribute.MirroredStrategy()\n!pip install basemap\n!pip install basemap-data\nimport pandas as pd\nimport numpy as np\nfrom numpy import expand_dims\nimport numpy.ma as ma\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport matplotlib.cm as mtpltcm\nfrom mpl_toolkits.mplot3d import Axes3D\nimport random\nimport folium\nfrom folium.plugins import HeatMap, HeatMapWithTime\nfrom folium import plugins\nfrom netCDF4 import Dataset\nimport cartopy.crs as ccrs\nimport pydub\nfrom scipy.io.wavfile import read, write\nimport librosa\nimport librosa.display\nimport IPython\nfrom IPython.display import Audio\nimport scipy\nfrom scipy import signal\nfrom scipy.fft import fftshift\n#from mpl_toolkits.basemap import Basemap\n\nfrom warnings import filterwarnings\n\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)\nfilterwarnings(\"ignore\", category=RuntimeWarning)\n\nimport os \nimport glob\nNETCDF_PATH1 = \"/kaggle/input/imdpunelowres/\"\nNETCDF_PATH2= \"/kaggle/input/imdpunehighres/\"\nfiles1 = glob.glob(os.path.join(NETCDF_PATH1, \"*.nc\"))\nfiles2= glob.glob(os.path.join(NETCDF_PATH2, \"*.nc\"))\nprint(files1)\nprint(files2)\n\nNETCDF_lowres= [Dataset(file,more=\"r\") for file in files1]\nNETCDF_highres= [Dataset(file,more=\"r\") for file in files2]\n\nHigh_Res_dataset=[]\nLow_Res_dataset=[]\nfor i in range(len(NETCDF_lowres)):\n    for j in range(NETCDF_lowres[i].variables[\"RAINFALL\"].shape[0]):\n        Datapoint=np.array(NETCDF_lowres[i].variables[\"RAINFALL\"][j,:,:])\n        if (np.amax(Datapoint)!=0):\n            Datapoint=Datapoint/np.amax(Datapoint)\n            Datapoint[Datapoint<0]=-1.0\n            Datapoint=Datapoint[1:,1:-2]\n            Low_Res_dataset.append(Datapoint)\n    for j in range(NETCDF_highres[i].variables[\"RAINFALL\"].shape[0]):\n        Datapoint=np.array(NETCDF_highres[i].variables[\"RAINFALL\"][j,:,:])\n        if (np.amax(Datapoint)!=0):\n            Datapoint=Datapoint/np.amax(Datapoint)\n            Datapoint[Datapoint<0]=-1.0\n            Datapoint=Datapoint[1:,3:-4]\n            High_Res_dataset.append(Datapoint)\n\nLow_Res_dataset=np.array(Low_Res_dataset)\nHigh_Res_dataset=np.array(High_Res_dataset)\nHigh_Res_dataset = expand_dims(High_Res_dataset, axis=-1)\nLow_Res_dataset = expand_dims(Low_Res_dataset, axis=-1)\nHigh_Res_dataset = High_Res_dataset.astype('float32')\nLow_Res_dataset = Low_Res_dataset.astype('float32')\nprint(len(Low_Res_dataset))\nprint(len(High_Res_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-09-19T08:09:55.553991Z","iopub.execute_input":"2023-09-19T08:09:55.554428Z","iopub.status.idle":"2023-09-19T08:11:00.003836Z","shell.execute_reply.started":"2023-09-19T08:09:55.554392Z","shell.execute_reply":"2023-09-19T08:11:00.001583Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
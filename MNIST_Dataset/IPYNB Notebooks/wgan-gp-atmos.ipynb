{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom numpy import expand_dims\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randn\nfrom numpy.random import randint\nfrom keras.datasets.mnist import load_data\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import Reshape\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Add\nfrom keras.layers import AveragePooling2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dropout\nfrom keras.layers import Embedding\nfrom keras.layers import Concatenate\nfrom keras.layers import GaussianNoise\nfrom keras.layers import BatchNormalization\nfrom keras.layers import LayerNormalization\n\nfrom keras.initializers import RandomNormal\nimport keras.backend as K\nMNIST_DATA = keras.datasets.mnist\n\n# define the standalone discriminator model\ndef define_discriminator(in_shape=(28,28,1), n_classes=10):\n\t# label input\n  in_label = Input(shape=(1,))\n\t# embedding the label input\n  li = Embedding(n_classes, 50)(in_label)\n\t# scale up to image dimensions with linear activation\n  n_nodes = in_shape[0]*in_shape[1]\n  li = Dense(n_nodes)(li)\n\t# reshape to additional channel\n  li = Reshape((in_shape[0], in_shape[1], 1))(li)\n  # image input\n  in_img = Input(shape=in_shape)\n  #KERNEL INItialization\n  init = RandomNormal(mean=0.0, stddev=0.02)\n  in_image = Concatenate()([in_img,li])\n  in_image=GaussianNoise(0.01)(in_image)\n  #add a convolutional layers\n  fe = Conv2D(128, (3,3), strides=(1,1), padding='same',kernel_initializer=init)(in_image)\n  fe = LayerNormalization()(fe)\n  fe = LeakyReLU(alpha=0.2)(fe)\n  # add 1st residual layer to the discriminator\n  pre_fe = Conv2D(128, (3,3), strides=(1,1), padding='same',kernel_initializer=init)(fe)\n  pre_fe = LayerNormalization()(pre_fe)\n  pre_fe = LeakyReLU(alpha=0.2)(pre_fe)\n  # add 2nd residual layer to the discriminator\n  pre_fe=Conv2D(128, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(pre_fe)\n  pre_fe = LayerNormalization()(pre_fe)\n  res_lay1 = Add()([fe, pre_fe])\n  res_lay1 = LeakyReLU(alpha=0.2)(res_lay1)\n  # downsample\n  fe = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(res_lay1)\n  fe = LayerNormalization()(fe)\n  fe = LeakyReLU(alpha=0.2)(fe)\n  # add 1st residual layer to the discriminator\n  #post_fe=Conv2D(128, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(fe)\n  #post_fe = BatchNormalization(synchronized=False)(post_fe)\n  #post_fe = LeakyReLU(alpha=0.2)(post_fe)\n  # add 2nd residual layer to the discriminator\n  #post_fe=Conv2D(128, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(post_fe)\n  #post_fe = BatchNormalization(synchronized=False)(post_fe)\n  #res_lay2 = Add()([fe, post_fe])\n  #res_lay2 = LeakyReLU(alpha=0.2)(res_lay2)\n\t#downsample\n  fe = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(fe)\n  fe = LayerNormalization()(fe)\n  fe = LeakyReLU(alpha=0.2)(fe)\n\t# flatten feature maps\n  fe = Flatten()(fe)\n\t# dropout\n  fe = Dropout(0.3)(fe)\n  # output\n  out_layer = Dense(1)(fe)\n\t# define model\n  model = Model(inputs=[in_img,in_label], outputs= out_layer, name=\"discriminator\")\n\t# compile model\n  #opt = Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.9) #try beta_1=0 as well\n  #model.compile(loss= discloss, optimizer=opt, metrics=['accuracy'])\n  return model\n\n# define the standalone generator model\ndef define_generator(low_res=(7,7,1), n_classes=10):\n\t  # label input\n    in_label = Input(shape=(1,))\n\t# embedding the label input\n    li = Embedding(n_classes, 50)(in_label)\n\t# scale up to image dimensions with linear activation\n    n_nodes = low_res[0]*low_res[1]\n    li = Dense(n_nodes)(li)\n\t# reshape to additional channel\n    li = Reshape((low_res[0], low_res[1], 1))(li)\n    # image generator input\n    in_img = Input(shape=low_res)\n    in_image= Concatenate()([in_img,li])\n    input_img=GaussianNoise(0.01)(in_image)\n    init = RandomNormal(mean=0.0, stddev=0.02)\n    #add initial conv2d layer\n    fir_gen = Conv2D(128, (3,3), strides=(1,1), padding='same',kernel_initializer=init)(input_img)\n    fir_gen = BatchNormalization(synchronized=False)(fir_gen)\n    fir_gen = LeakyReLU(alpha=0.2)(fir_gen)\n    # add 1st residual layer to the generator\n    pre_gen = Conv2D(128, (3,3), strides=(1,1), padding='same',kernel_initializer=init)(fir_gen)\n    pre_gen = BatchNormalization(synchronized=False)(pre_gen)\n    pre_gen = LeakyReLU(alpha=0.2)(pre_gen)\n    # add 2nd residual layer to the generator\n    pre_gen = Conv2D(128, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(pre_gen)\n    pre_gen = BatchNormalization(synchronized=False)(pre_gen)\n    pre_gen = Add()([fir_gen, pre_gen])\n    pre_gen = LeakyReLU(alpha=0.2)(pre_gen)\n    # upsample to 28x28\n    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(pre_gen)\n    gen = BatchNormalization(synchronized=False)(gen)\n    gen = LeakyReLU(alpha=0.2)(gen)\n    #2nd upsampling\n    gen2 = Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n    gen2 = BatchNormalization(synchronized=False)(gen2)\n    gen2 = LeakyReLU(alpha=0.2)(gen2)\n  # output\n    out_layer = Conv2D(1, (5,5), activation='tanh', padding='same')(gen2)\n\t# define model\n    model = Model(inputs=[in_img,in_label], outputs=out_layer, name=\"generator\")\n    return model\n\n\n\n# define the combined generator and discriminator model, for updating the generator\n#def define_gan(g_model, d_model):\n\t# make weights in the discriminator not trainable\n\t#d_model.trainable = False\n\t# get noise and label inputs from generator model\n\t#gen_noise, gen_label = g_model.input\n\t# get image output from the generator model\n\t#gen_output = g_model.output\n\t# connect image output and label input from generator as inputs to discriminator\n\t#gan_output = d_model([gen_output, gen_label])\n\t# define gan model as taking noise and label and outputting a classification\n\t#model = Model([gen_noise, gen_label], gan_output)\n\t# compile model\n\t##opt = Adam(learning_rate=0.0001, beta_1=0.2)\n\t#model.compile(loss='binary_crossentropy', optimizer=opt)\n\t#return model\n\n\n\nclass WGAN(keras.Model):\n    def __init__(self, discriminator, generator, Dsteps=5, gp_weight=10.0):\n        super(WGAN, self).__init__()\n\n        self.discriminator = discriminator\n        self.generator = generator\n        self.d_steps = Dsteps\n        self.gp_weight = gp_weight\n\n    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n        super(WGAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.d_loss_fn = d_loss_fn\n        self.g_loss_fn = g_loss_fn\n    \n    def generate_low_res_samples(self,image, labels):\n        #print(batch_size)\n        Avgpool= AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')\n        #ix = randint(0, 60000, batch_size)\n        # select images\n        #random_images= images[ix]\n        low1=Avgpool(image)\n        low2=Avgpool(low1)\n        #print(low2.shape)\n        return low2,labels\n\n    def gradient_penalty (self,batch_size, real_images, fake_images, real_labels):\n        # Get the interpolated image\n        #print(real_images.shape)\n        #print(fake_images.shape)\n        alpha = tf.random.uniform(shape=[1,1,1], minval=0.,maxval=1.)\n        diff = fake_images - real_images\n        interpolated = real_images + alpha * diff\n\n        with tf.GradientTape() as gp_tape:\n            gp_tape.watch(interpolated)\n            pred = self.discriminator([interpolated,real_labels], training=True)\n\n        grads = gp_tape.gradient(pred, [interpolated])[0]\n        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n        gp = tf.reduce_mean((norm - 1.0) ** 2)\n        return gp                             \n\n    def train_step(self, real_data):\n        if isinstance(real_data, tuple):\n            real_images = real_data[0]\n            real_labels = real_data[1]\n            #print(real_labels.shape)\n\n\n        for i in range(self.d_steps):\n            # Get the lowres image\n            [lowres_images, lowres_labels]= self.generate_low_res_samples(real_images, real_labels)\n         \n            with tf.GradientTape() as tape:\n                # Generate fake images from the latent vector\n                fake_images = self.generator([lowres_images, lowres_labels], training=True)\n                # Get the logits for the fake images\n                fake_logits = self.discriminator([fake_images,lowres_labels], training=True)\n                # Get the logits for the real images\n                real_logits = self.discriminator([real_images,real_labels], training=True)\n\n                # Calculate the discriminator loss using the fake and real image logits\n                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n                # Calculate the gradient penalty\n                gp = self.gradient_penalty(batch_size, real_images, fake_images,real_labels)\n                # Add the gradient penalty to the original discriminator loss\n                d_loss = d_cost + gp * self.gp_weight\n\n            # Get the gradients w.r.t the discriminator loss\n            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n            # Update the weights of the discriminator using the discriminator optimizer\n            self.d_optimizer.apply_gradients(zip(d_gradient, self.discriminator.trainable_variables))\n\n        # Train the generator\n        [lowres_images, lowres_labels]= self.generate_low_res_samples(real_images,real_labels)\n        with tf.GradientTape() as tape:\n            # Generate fake images using the generator\n            generated_images = self.generator([lowres_images, lowres_labels], training=True)\n            # Get the discriminator logits for fake images\n            gen_img_logits = self.discriminator([generated_images, lowres_labels], training=True)\n            # Calculate the generator loss\n            g_loss = self.g_loss_fn(gen_img_logits)\n\n        # Get the gradients w.r.t the generator loss\n        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n        # Update the weights of the generator using the generator optimizer\n        self.g_optimizer.apply_gradients(zip(gen_gradient, self.generator.trainable_variables))\n        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n\n\n# load  mnist images\ndef load_samples(MNIST_DATA):\n\t# load dataset\n    (trainX, trainy), (_, _) = MNIST_DATA.load_data()\n\t# expand to 3d, e.g. add channels\n    X = expand_dims(trainX, axis=-1)\n    trainy = expand_dims(trainy, axis=-1)\n\t# convert from ints to floats\n    X = X.astype('float32')\n\t# scale from [0,255] to [-1,1]\n    X = (X - 127.5) / 127.5\n    #print(X.shape, trainy.shape)\n    return [X, trainy]\n\n#def generate_low_res_samples():\n #     [images, labels]= \n #     Avgpool= AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')\n #     ix = randint(0, images.shape[0], batch_size)\n #     # select images\n #     random_images= images[ix]\n #     labels=labels[ix]\n #     low1=Avgpool(random_images)\n #     low2=Avgpool(low1)\n      #print(low2.shape)\n #     return low2,labels\n\nclass GANMonitor(keras.callbacks.Callback):\n    def __init__(self, num_img=6):\n        self.num_img = num_img\n\n    def on_epoch_end(self, epoch, logs=None):\n        g_model.save('WGAN_GP%.1f.keras'%epoch)\n\ncbk = GANMonitor(num_img=3)\n#loading the data \norg_dataset = load_samples(MNIST_DATA)\n#print(org_dataset[1].shape)\n#print(train_images.type, train_labels.type)\n# define the generator and the discriminator model\ng_model=define_generator()\nd_model= define_discriminator()\n\n#define the optimizer for the generator(G) and discriminator(D)\ngenerator_optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\ndiscriminator_optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n\n#Loss functions for G and D without the Gradient penalty\ndef discriminator_loss(real_img, fake_img):\n      real_loss = tf.reduce_mean(real_img)\n      fake_loss = tf.reduce_mean(fake_img)\n      return fake_loss - real_loss\n\ndef generator_loss(fake_img):\n      return -tf.reduce_mean(fake_img)\n\n# Instantiate the WGAN model.\nwgan = WGAN(discriminator=d_model, generator=g_model, Dsteps=3,)\n\n# Compile the WGAN model.\nwgan.compile(d_optimizer=discriminator_optimizer, g_optimizer=generator_optimizer, g_loss_fn=generator_loss, d_loss_fn=discriminator_loss,)\nepoch =50\ntotal_samples=org_dataset[0].shape[0]\nbatch_size=256\nsteps_per_epoch=total_samples//batch_size\n# Start training the model.\nwgan.fit(org_dataset[0],org_dataset[1], batch_size=batch_size, epochs=epoch,callbacks=[cbk],steps_per_epoch=steps_per_epoch)","metadata":{},"execution_count":null,"outputs":[]}]}
# Atmospheric-Super-Resolution
Using WGAN-GP to downscale atmospheric fields
IMPORTANT POINTS REGARDING DIFFERENT DATASET AND HOW TO USE THE SAVED MODELS. The Notebooks are made on Kaggle platform and trained using GPU T4 x 2. Keras has been chosen as our deep learning platform on python.

1) MNIST_Dataset

This notebook takes the well known MNIST DATASET to showcase the use of W-GAN's (Wasserstein Generative Adversarial Networks) to increase the resolution of images by 4x.

The Data is initally downsampled from original (28 x 28) to (7 x 7) using either (Maxpooling or Avgpooling layers). This data is then fed as our input to the model. The trained models use (7x7) as image inputs and output a (28 x 28) resoultion images. The input format for the generator is (None, 7, 7, 1). 

We have used the WGAN's with gradient penalty (WGAN-GP) term throughout for all the others dataset as well. The advantage is that no hyper-parameter tuning is required in case of WGAN-GP. To learn more refer to : Improved Training of Wasserstein GANs by Ishaan Gulrajani et al. (https://arxiv.org/abs/1704.00028).


2) IMD_Rainfall Dataset

THE MODEL USES TWO IMD DATASET OF RAINFALL AVAILABLE ON THEIR WEBSITE. THE LOW RESOLUTION (1 x 1 degree) and the HIGH RESOLUTION (0.25 x 0.25 degree). Both are actual gauge+satellite observational dataset. The time period taken to train is 42 years chosen in different bracket of 1951-1970 and 2001-2022. The low resolution images are 32 x 32 pixels and therefore is the standard size of input for the trained models as well. The output is at 128 x 128 pixels images from the generator of WGAN_GP. The input format for the generator is (None, 32, 32, 1).

The data standardization is done to bring down the precipitation values between [-1,1]. To acheive every individual datapoint is scaled down by the highest recoreded rainfall on that particular day. (Better and more uniform methods of scaling can be explored). All the masked values that make up the border of India are mapped to -1. Also the output from the geenrator is not perfect in producing a zero output in case of no rainfall. To counter this all negative values in the model output very close to zero are mapped to zero as negative rainfall makes no sense in our mapping. While the rest of the negative values are the mask values to mark the country borders. Fractional Skill Score is a metric used for measuring the performance of our network. To read more on FSS score: CIRA GUIDE TO CUSTOM LOSS FUNCTIONS FOR NEURAL NETWORKS IN ENVIRONMENTAL SCIENCES (https://arxiv.org/abs/2106.09757).


3) ERA_Rainfall Dataset

ERA Rainfall is a hourly dataset and our high-res comparison is a IMD Daily dataset. The original resolution of ERA is 0.25 x 0.25 degree but for our super-resolution purposes we are lowering this to 1 x 1 degree. The additional information apart from total precipitation is used according to the paper: Increasing the accuracy and resolution of precipitation forecasts using deep generative models by Ilan Price et al. (arXiv:2203.12297v1). The use of different fields can be experimented with. The input data block is of the shape (None, 24, 12, 12, 5). Where the 24 channel is the accumulation of hours in a day and the the 5 channel input of diiferent atomospheric fields. The trained models also uses the same input but only wiith 3 fields (Total Precipitation, Total Column Water, Temperature 2m). Apart from this the map of India is also divided into 5 regions as this serves two purposes- i) allow for more number of datapoints and ii) smaller size of the input and output matrix means faster GPU processing time. The scaling used is same as above in the IMD_Rainfall dataset.

The generator design is taken from the above mentioned paper with network divided into two segments. Low-Res Coorection and the Super resoultion. More architecutre details can be found on the slides with modified loss function. The oscillatory behaviour shown in the training through loss function is a question of examintation and perhaps can be handled by the use of different optimizer at later stages of the training as found in this paper: Stochastic Super-Resolution for Downscaling Time-Evolving Atmospheric Fields with a Generative Adversarial Network by Leinonen et al. (https://arxiv.org/abs/2005.10374). The training is divided into two fit functions. The pretraining that corrects the input at low resolution and the WGAN training. 

Results are again measured using the FSS metric. The comparison is done with the original ERA data at 0.25 degree and our downscaled data by WGAN-GP to the IMD observational data and the results are presented on the slides. Clearly the FSS scores have been improved. However the model still lacks in predicting the extreme events well as shown by heavy rainfall and high precipitation thresholds in FSS metric. One can look at the ensemble predictions by generating multiple model outptus using the same generator with different noise alongside input and compute the CRPS metric. 

4) Temperature Dataset 

Precipitation is very to predict at high resolutions. Probably on of the hardest amongst the atmospheric fields. The reason to do this dataset was to look at how the same network is performing on a easier field as Temperature. Since temperature has a more uniform spread and gradual variations and low chances of extreme events it is an ideal method to test against a new model. The task here is again super-resolution by 4x. And this time IMD Maximum temperature daily data is used as input to the model. The input to the generator and the trained models is of shape (None, 12, 12, 1). The High resolution comparison used is the ERA Data at 0.25 degree. Since it is at an hourly frequency, daily maximum has been extracted to form the final data. The scaling used here more uniform than the rainfall data. We divide the complete dataset by maximum ever recorded temperature in India i.e. 51 degree celcius to scale it between [-1,1]. Again the map of India is divided into five segments for above mentioned two reasons. 

The model architecture remains the same with only slight modifications to take into the account the different shape of the input data. The training is done in two parts- pretraing and the WGAN. The WGAn training is continued in two runs due to notebook time restrictions in Kaggle for this the models are saved and loaded to continue the training. The graphs of two sets of data spanning for 3 years are used to check for overfitting. One data is what the architecture has already seen ( Training data) and the test data which is new to the model (Test Data). RMSE metric is used to compare the performance of the model on both of them. And from the graph it can be seem that the error follows similar trends indicating that it can be run for few nore epochs as both are showing a decreasing trend. Again one can look at the ensemble predictions by generating multiple model outptus using the same generator with different noise alongside input and compute the CRPS metric.
